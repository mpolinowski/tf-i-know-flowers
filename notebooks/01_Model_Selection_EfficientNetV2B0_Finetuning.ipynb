{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64eece7d",
   "metadata": {},
   "source": [
    "# Tensorflow Image Classifier\n",
    "\n",
    "## EfficientNetV2B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd146210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay)\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.io import TFRecordWriter\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks  import (\n",
    "    Callback,\n",
    "    CSVLogger,\n",
    "    EarlyStopping,\n",
    "    LearningRateScheduler,\n",
    "    ModelCheckpoint\n",
    ")\n",
    "from tensorflow.keras.layers import (\n",
    "    Layer,\n",
    "    GlobalAveragePooling2D,\n",
    "    Conv2D,\n",
    "    MaxPool2D,\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    InputLayer,\n",
    "    BatchNormalization,\n",
    "    Input,\n",
    "    Dropout,\n",
    "    RandomFlip,\n",
    "    RandomRotation,\n",
    "    RandomContrast,\n",
    "    RandomBrightness,\n",
    "    Resizing,\n",
    "    Rescaling\n",
    ")\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy, TopKCategoricalAccuracy, SparseCategoricalAccuracy\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import L2, L1\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.train import Feature, Features, Example, BytesList, Int64List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b9599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH = 32\n",
    "SIZE = 224\n",
    "SEED = 42\n",
    "\n",
    "EPOCHS = 20\n",
    "LR = 0.001\n",
    "FILTERS = 6\n",
    "KERNEL = 3\n",
    "STRIDES = 1\n",
    "REGRATE = 0.0\n",
    "POOL = 2\n",
    "DORATE = 0.05\n",
    "LABELS = ['Gladiolus', 'Adenium', 'Alpinia_Purpurata', 'Alstroemeria', 'Amaryllis', 'Anthurium_Andraeanum', 'Antirrhinum', 'Aquilegia', 'Billbergia_Pyramidalis', 'Cattleya', 'Cirsium', 'Coccinia_Grandis', 'Crocus', 'Cyclamen', 'Dahlia', 'Datura_Metel', 'Dianthus_Barbatus', 'Digitalis', 'Echinacea_Purpurea', 'Echinops_Bannaticus', 'Fritillaria_Meleagris', 'Gaura', 'Gazania', 'Gerbera', 'Guzmania', 'Helianthus_Annuus', 'Iris_Pseudacorus', 'Leucanthemum', 'Malvaceae', 'Narcissus_Pseudonarcissus', 'Nerine', 'Nymphaea_Tetragona', 'Paphiopedilum', 'Passiflora', 'Pelargonium', 'Petunia', 'Platycodon_Grandiflorus', 'Plumeria', 'Poinsettia', 'Primula', 'Protea_Cynaroides', 'Rose', 'Rudbeckia', 'Strelitzia_Reginae', 'Tropaeolum_Majus', 'Tussilago', 'Viola', 'Zantedeschia_Aethiopica']\n",
    "NLABELS = len(LABELS)\n",
    "DENSE1 = 1024\n",
    "DENSE2 = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aca3ff",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7436d635",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory = '../dataset/Flower_Dataset/split/train'\n",
    "test_directory = '../dataset/Flower_Dataset/split/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b7bb62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = image_dataset_from_directory(\n",
    "    train_directory,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    class_names=LABELS,\n",
    "    color_mode='rgb',\n",
    "    batch_size=BATCH,\n",
    "    image_size=(SIZE, SIZE),\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    "    interpolation='bilinear',\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False\n",
    ")\n",
    "\n",
    "# Found 9206 files belonging to 48 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d512599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = image_dataset_from_directory(\n",
    "    test_directory,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    class_names=LABELS,\n",
    "    color_mode='rgb',\n",
    "    batch_size=BATCH,\n",
    "    image_size=(SIZE, SIZE),\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# Found 3090 files belonging to 48 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1958f4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = Sequential([\n",
    "        # Resizing(224, 224),\n",
    "        RandomRotation(factor=0.25),\n",
    "        RandomFlip(mode='horizontal'),\n",
    "        RandomContrast(factor=0.1),\n",
    "        RandomBrightness(0.1)\n",
    "    ],\n",
    "    name=\"img_augmentation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b5b896",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = (\n",
    "    train_dataset\n",
    "    .map(lambda image, label: (data_augmentation(image), label))\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "\n",
    "testing_dataset = (\n",
    "    test_dataset.prefetch(\n",
    "        tf.data.AUTOTUNE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6e8419",
   "metadata": {},
   "source": [
    "## Building the Efficient TF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcb2b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer learning\n",
    "\n",
    "backbone = tf.keras.applications.EfficientNetV2B0(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(SIZE, SIZE, 3),\n",
    "    include_preprocessing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a753a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5b2abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient_model = tf.keras.Sequential([\n",
    "    Input(shape=(SIZE, SIZE, 3)),\n",
    "    data_augmentation,\n",
    "    backbone,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(DENSE1, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(DENSE2, activation='relu'),\n",
    "    Dense(NLABELS, activation='softmax')\n",
    "])\n",
    "\n",
    "efficient_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bd3647",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    '../best_weights',\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1,\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0586c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a8447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [CategoricalAccuracy(name='accuracy')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265e157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient_model.compile(\n",
    "    optimizer = Adam(learning_rate=LR),\n",
    "    loss = loss_function,\n",
    "    metrics = metrics,\n",
    "    # callbacks = ['checkpoint_callback']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da4a656",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a89a72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "efficient_history = efficient_model.fit(\n",
    "    training_dataset,\n",
    "    validation_data = testing_dataset,\n",
    "    epochs = EPOCHS,\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "# loss: 0.2039\n",
    "# accuracy: 0.9343\n",
    "# val_loss: 0.3764\n",
    "# val_accuracy: 0.9026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f16855",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9a3c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient_model.evaluate(testing_dataset)\n",
    "#  loss: 0.3764 - accuracy: 0.9026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e441ce9d-500c-4a4f-8e66-31046726f007",
   "metadata": {},
   "source": [
    "### Model Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f917a1-1177-4740-b52d-b5c28b9f0b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95dbe0d-da72-4f86-907f-0d556308d62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient_model.compile(\n",
    "    optimizer = Adam(learning_rate=LR/100),\n",
    "    loss = loss_function,\n",
    "    metrics = metrics,\n",
    "    # callbacks = ['checkpoint_callback']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac37be3e-6f59-4620-9bc7-7f4134b2870e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "efficient_history = efficient_model.fit(\n",
    "    training_dataset,\n",
    "    validation_data = testing_dataset,\n",
    "    epochs = EPOCHS,\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "# loss: 0.2119\n",
    "# accuracy: 0.9344\n",
    "# val_loss: 0.3779\n",
    "# val_accuracy: 0.9084"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427e3f9f-efdd-40a2-b49d-3298b40de089",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d37c7d8-8767-4d0a-965c-5c98f17d15e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient_model.evaluate(testing_dataset)\n",
    "# loss: 0.3490 - accuracy: 0.9013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62952534",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(efficient_history.history['loss'])\n",
    "plt.plot(efficient_history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'val_loss'])\n",
    "plt.savefig('assets/EfficientNetV2B0_01.webp', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f833ed",
   "metadata": {},
   "source": [
    "![tf Emotion Detection](./assets/EfficientNetV2B0_01.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437119fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(efficient_history.history['accuracy'])\n",
    "plt.plot(efficient_history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_accuracy', 'val_accuracy'])\n",
    "plt.savefig('assets/EfficientNetV2B0_02.webp', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fab59d",
   "metadata": {},
   "source": [
    "![tf Emotion Detection](./assets/EfficientNetV2B0_02.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4874d28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_image_bgr = cv.imread('../dataset/snapshots/Viola_Tricolor.jpg')\n",
    "test_image_resized = cv.resize(test_image_bgr, (SIZE, SIZE))\n",
    "test_image_rgb = cv.cvtColor(test_image_resized, cv.COLOR_BGR2RGB)\n",
    "img = tf.constant(test_image_rgb, dtype=tf.float32)\n",
    "img = tf.expand_dims(img, axis=0)\n",
    "\n",
    "probs = efficient_model(img).numpy()\n",
    "label = LABELS[tf.argmax(probs, axis=1).numpy()[0]]\n",
    "\n",
    "print(label, str(probs[0]))\n",
    "\n",
    "plt.imshow(test_image_rgb)\n",
    "plt.title(label)\n",
    "plt.axis('off')\n",
    "        \n",
    "plt.savefig('assets/EfficientNetV2B0_Prediction_01.webp', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e471a1-5183-42d9-97db-13acd43b4dbb",
   "metadata": {},
   "source": [
    "![tf Emotion Detection](./assets/EfficientNetV2B0_Prediction_01.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437bbd84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_image_bgr = cv.imread('../dataset/snapshots/Strelitzia.jpg')\n",
    "test_image_resized = cv.resize(test_image_bgr, (SIZE, SIZE))\n",
    "test_image_rgb = cv.cvtColor(test_image_resized, cv.COLOR_BGR2RGB)\n",
    "img = tf.constant(test_image_rgb, dtype=tf.float32)\n",
    "img = tf.expand_dims(img, axis=0)\n",
    "\n",
    "probs = efficient_model(img).numpy()\n",
    "label = LABELS[tf.argmax(probs, axis=1).numpy()[0]]\n",
    "\n",
    "print(label, str(probs[0]))\n",
    "\n",
    "plt.imshow(test_image_rgb)\n",
    "plt.title(label)\n",
    "plt.axis('off')\n",
    "        \n",
    "plt.savefig('assets/EfficientNetV2B0_Prediction_02.webp', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b0728d-fb1e-404f-8053-c9942a694efc",
   "metadata": {},
   "source": [
    "![tf Emotion Detection](./assets/EfficientNetV2B0_Prediction_02.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a101733",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_image_bgr = cv.imread('../dataset/snapshots/Water_Lilly.jpg')\n",
    "test_image_resized = cv.resize(test_image_bgr, (SIZE, SIZE))\n",
    "test_image_rgb = cv.cvtColor(test_image_resized, cv.COLOR_BGR2RGB)\n",
    "img = tf.constant(test_image_rgb, dtype=tf.float32)\n",
    "img = tf.expand_dims(img, axis=0)\n",
    "\n",
    "probs = efficient_model(img).numpy()\n",
    "label = LABELS[tf.argmax(probs, axis=1).numpy()[0]]\n",
    "\n",
    "print(label, str(probs[0]))\n",
    "\n",
    "plt.imshow(test_image_rgb)\n",
    "plt.title(label)\n",
    "plt.axis('off')\n",
    "        \n",
    "plt.savefig('assets/EfficientNetV2B0_Prediction_03.webp', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c30e61-6983-46b0-8ca7-70214898b815",
   "metadata": {},
   "source": [
    "![tf Emotion Detection](./assets/EfficientNetV2B0_Prediction_03.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1c5ccc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "\n",
    "for images, labels in testing_dataset.take(1):\n",
    "    for i in range(16):\n",
    "        ax = plt.subplot(4,4,i+1)\n",
    "        true = \"True: \" + LABELS[tf.argmax(labels[i], axis=0).numpy()]\n",
    "        pred = \"Predicted: \" + LABELS[\n",
    "            tf.argmax(efficient_model(tf.expand_dims(images[i], axis=0)).numpy(), axis=1).numpy()[0]\n",
    "        ]\n",
    "        plt.title(\n",
    "           true  + \"\\n\" + pred\n",
    "        )\n",
    "        plt.imshow(images[i]/255.)\n",
    "        plt.axis('off')\n",
    "        \n",
    "plt.savefig('assets/EfficientNetV2B0_03.webp', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525f7bc7",
   "metadata": {},
   "source": [
    "![tf Emotion Detection](./assets/EfficientNetV2B0_03.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2d6379",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_test = []\n",
    "\n",
    "for img, label in testing_dataset:\n",
    "    y_pred.append(efficient_model(img))\n",
    "    y_test.append(label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d60e112",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conf_mtx = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=confusion_matrix(\n",
    "        np.argmax(y_test[:-1], axis=-1).flatten(),\n",
    "        np.argmax(y_pred[:-1], axis=-1).flatten()\n",
    "    ),\n",
    "    display_labels=LABELS\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,12))\n",
    "conf_mtx.plot(ax=ax, cmap='plasma', include_values=True, xticks_rotation='vertical',)\n",
    "\n",
    "plt.savefig('assets/EfficientNetV2B0_04.webp', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfd858c",
   "metadata": {},
   "source": [
    "![tf Emotion Detection](./assets/EfficientNetV2B0_04.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161e8e5d",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34edfc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.saving.save_model(\n",
    "    efficient_model, '../saved_model/efficientv2b0_model/1', overwrite=True, save_format='tf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcce9446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore the model\n",
    "restored_model = tf.keras.saving.load_model('../saved_model/efficientv2b0_model/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d31396",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(restored_model.signatures[\"serving_default\"].structured_input_signature[1].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a86023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check its architecture\n",
    "restored_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ecf8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "restored_model.evaluate(testing_dataset)\n",
    "# loss: 0.3779 - accuracy: 0.9084"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
